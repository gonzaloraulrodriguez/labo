glimpse(vehiculos) #DEscribe datos
#Librerias
library(readxl)
library(dplyr)
glimpse(vehiculos) #DEscribe datos
resis <- vehiculos$Resistencia
#Estadisticos
summary(resis)
View(media <-mean(resis))
media <-mean(resis)
media
#Promedio
media <-mean(resis)
media
#Mediana
mediana <-median(resis)
#Mediana
mediana <-median(resis)
mediana
install.packages("modeest")
#Moda
moda <- mode(resis)
moda
#Moda
moda <- mfv(resis)
#Librerias
library(readxl)
library(dplyr)
library(modeest)
#Moda
moda <- mfv(resis)
moda
#Max y Min
max(resis)
min(resis)
#Cuantiles
quantile(resis)
#Rango
range(resis)
#Desviacion estandar
sd(resis)
#Varianza muestral
var(resis)
#Coheficiente de variación
CV = (sd(resis)/mean(resis)) * 100
CV
#Rango intercuartilico
IQR(reses)
#Rango intercuartilico
IQR(resis)
install.packages("fBasics")
knitr::opts_chunk$set(echo = TRUE)
library(fBasics)
library(e1071)
install.packages("e1071")
library(fBasics)
library(e1071)
skewness(resis)
library(fBasics)
library(e1071)
skewness(resis)
#Curtosis
kurtosis(resis)
stem(resis)
#Numero de intervalos
nclass.Sturges(resis)
#Limite de los intervalos
seq(120,150,length= nclass.Sturges(resis))
#Limite de los intervalos
limite = seq(120,150,length= nclass.Sturges(resis))
#Limite de los intervalos
limite = seq(120,150,length= nclass.Sturges(resis))
interv_resis <- cut(resis,break = limite, include.lowest=TRUE)
interv_resis <- cut(resis,breaks = limite, include.lowest=TRUE)
#Mostramos los intervalores de resistencia en una tabla
table(interv_resis)
#Histograma
hist(resis, breaks = limite)
#Histograma
hist(resis, breaks = limite, main = "Histograma de la variable Resistencia")
#Histograma
hist(resis, breaks = limite, main = "Histograma de la variable Resistencia", col = "Red, xlab= "Intervalos", ylab = "Frecuencia")
#Histograma
hist(resis, breaks = limite, main = "Histograma de la variable Resistencia", col = "Red", xlab= "Intervalos", ylab = "Frecuencia")
knitr::opts_chunk$set(echo = TRUE)
n_i <- nclass.Sturges(edades)
#Librerias
library(dplyr)
library(modeest)
#Cargamos datos en un vector para su uso
edades <- c(21,23,56,74,55,27,23,89,77,48,77,77,76,33,23,22,55,62,64,65,77,47,45,45,45,
65,42,48,49,52,53,44,45,23,78,77,67,88,36,38,78,74,46,36,30,33,23,24,55,77,25,46,40,23,45,66,76)
#Promedio
media <-mean(edades)
media
#Mediana
mediana <-median(edades)
mediana
#Moda
moda <- mfv(edades)
moda
#Max y Min
max(edades)
min(edades)
#Cuantiles
quantile(edades)
#Rango
range(edades)
#Desviacion estandar
sd(edades)
#Varianza muestral
var(edades)
#Coheficiente de variación
CV = (sd(edades)/mean(edades)) * 100
CV
#Rango intercuartilico
IQR(edades)
n_i <- nclass.Sturges(edades)
# Distribucion de frecuencias absolutas, relativas, porcentuales:
library(fdth)
tabla_frec <-fdt_cat(edades)
#Limite de los intervalos:
limite <- seq(20,90,length= n_i)
#Limite de los intervalos:
#limite <- seq(20,90,length= n_i)
limite <- seq(20,90,by=10)
#Amplitud de intervalos:
a_i <- 10
#Limite de los intervalos:
#limite <- seq(20,90,length= n_i)
limite <- seq(20,90,by=a_i)
library(readxl)
tabla4 <-fdt_cat(edades)
knitr::opts_chunk$set(echo = TRUE)
Salud <- salud$Problemas
library(fdth)
menor_40
#Porcentaje de personas menores de 40 años:
menor_40 <- edades[edades<40]/count(edades)
#Porcentaje de personas menores de 40 años:
menor_40 <- edades[edades<40]/length(edades)
#Porcentaje de personas menores de 40 años:
menor_40 <- 100 * lenght(edades[edades<40])/length(edades)
#Porcentaje de personas menores de 40 años:
menor_40 <- 100 * length(edades[edades<40])/length(edades)
#Cantidad de personas [70;90):
entre_70_90 <- length(edades[edades >= 70 && edades < 90])
#Cantidad de personas [70;90):
entre_70_90 <- length(edades[edades >= 70 & edades < 90])
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
#Cargamos producciones:
Fertilizante_A <- c(30,25,28,29,30,31,24,22,25,27)
Fertilizante_B <- c(28,27,28,28,26,27,26,29)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
z.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
#Cargamos produccion anterior
Fertilizante_A_antes <- c(25,20,25,28,30,30,26,15,18,22)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
t.test(x=Fertilizante_A_antes,y=Fertilizante_A,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
leveneTest(Fertilizante_A_antes)
#Como ambas muestras tienen una distribución normal:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
library(car)
install.packages("car")
library(car)
leveneTest(Fertilizante_A_antes)
leveneTest(c(Fertilizante_A_antes, Fertilizante_A), rep(c("Gr1", "Gr2"), each = 15), center = "mean")
#Como ambas muestras tienen una distribución normal:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
library(effsize)
install.packages("effsize")
library(effsize)
cohen.d(Fertilizante_A_antes, Fertilizante_A, paired = FALSE)
cohen.d(Fertilizante_A_antes, Fertilizante_A, paired = FALSE, conf.level = 0.99)
cohen.d(Fertilizante_B, Fertilizante_A, paired = FALSE, conf.level = 0.98)
#Como ambas muestras tienen una distribución normal:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
# Distribucion de frecuencias absolutas, relativas, porcentuales:
library(fdth)
tabla4 <-fdt(edades)
tabla4
tabla4 <-fdt(edades,start = 20,end = 90,h = a_i)
tabla4
m_organica <- c(1.10,	5.09,	0.97,	1.59,	4.60,	0.32,	0.55,	1.45,	0.14,	4.47,
1.20,	3.50,	5.02,	4.67,	5.22,	2.69,	3.98,	3.17,	3.03,	2.21)
$Prueba
$\mu
$$\mu
#Cargamos los datos a un vector:
m_organica <- c(1.10,	5.09,	0.97,	1.59,	4.60,	0.32,	0.55,	1.45,	0.14,	4.47,
1.20,	3.50,	5.02,	4.67,	5.22,	2.69,	3.98,	3.17,	3.03,	2.21)
#Calculamos intervalos de confianza al 95%:
t.test(m_organica,conf.level = 0.95)$conf.int
#Calculamos intervalos de confianza al 95%:
t.test(m_organica,conf.level = 0.95)
shapiro.test(m_organica)
install.packages("car")
knitr::opts_chunk$set(echo = TRUE)
library("car")
leveneTest(m_organica)
c_1 <- c(102,86,98,109,92)
c_2 <- c(81,165,97,134,92,87,114)
#Prueba de normalidad:
shapiro.test(c_1)
#Creamos dataframe
peliculas <- data.frame(Companias=factor(c(rep("1",5),rep("2",7))),
Tiempo=c(c_1,c_2)) peliculas
#Creamos dataframe
peliculas <- data.frame(Companias=factor(c(rep("1",5),rep("2",7))),
Tiempo=c(c_1,c_2))
peliculas
#Prueba de Homocedasticidad:
library(car)
leveneTest(Tiempo~Companias, data = peliculas)
#Prueba de hipótesis:
t.test(c_1,c_2,paired = FALSE,alternative = "greater",conf.level = 0.90,
var.equal = TRUE, mu=10)
install.packages("xelatex")
install.packages("inputenc")
#Creamos dataframe:
fertilizantes <- data.frame(fert=factor(c(rep("A",5),rep("B",7)))
, peso=c(Fertilizante_A,Fertilizante_B))
#Creamos dataframe:
fertilizantes <- data.frame(fert=factor(c(rep("A",10),rep("B",8)))
, peso=c(Fertilizante_A,Fertilizante_B))
leveneTest(peso~fert, data = fertilizantes)
source('C:/Users/Gonzalo/Desktop/Py/Cazatalentos/intento_D_15K.r', echo=TRUE)
source('C:/Users/Gonzalo/Desktop/Py/Cazatalentos/intento_D_15K.r', echo=TRUE)
ftirar  <- function(prob, qty)
{
return(sum(runif(qty) < prob))
}
ftirar(0.7,10)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
vector
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
vector_bueno
vector_malo
lote1=c(29.39,31.51,30.88,27.63,28.85)
lote2=c(30.63,32.1,30.11,29.63,29.68)
lote3=c(27.16,26.63,25.31,27.66,27.1)
lote4=c(31.03,30.98,28.95,31.45,29.7)
lote5=c(29.67,29.32,26.87,31.59,29.41)
lote=cbind(lote1,lote2,lote3,lote4,lote5)
medias = apply(lote,2,mean)
desvios = apply(lote,2,sd)
salida = round(cbind(medias,desvios),3)
salida
mat_df = data.frame("Lote"=factor(c(rep(1,5),rep(2,5),rep(3,5),
rep(4,5),rep(5,5))),
"Resistencia"=c(lote1,lote2,lote3,lote4,lote5))
mat_df.aov=aov(Resistencia~Lote, data = mat_df)
mat_df.aov
summary(mat_df.aov)
pairwise.t.test(mat_df$Resistencia, mat_df$Lote, p.adj = "bonferroni")
TukeyHSD(mat_df.aov, "Lote")
jugadores=cbind(vector_bueno,vector_malo)
medias = apply(jugadores,2,mean)
desvios = apply(jugadores,2,sd)
salida = round(cbind(medias,desvios),3)
salida
mat_df = data.frame("Lote"=factor(c(rep(1,10),rep(2,10))),
"Resistencia"=c(vector_bueno,vector_malo))
ggplot(mat_df,aes(x=Lote, y=Resistencia, fill=Lote))+geom_boxplot()
mat_df.aov=aov(Resistencia~Lote, data = mat_df)
mat_df.aov
summary(mat_df.aov)
pairwise.t.test(mat_df$Resistencia, mat_df$Lote, p.adj = "bonferroni")
TukeyHSD(mat_df.aov, "Lote")
vector_bueno = c()
vector_malo = c()
vector_malo2 = c()
for (i in 1:10)
{
vector_bueno <- c(vector_bueno, ftirar(0.7,10))
vector_malo <- c(vector_malo, ftirar(0.6,10))
vector_malo2 <- c(vector_malo2, ftirar(0.55,10))
}
#vector <- c(vector, values[i])
jugadores=cbind(vector_bueno,vector_malo,vector_malo2)
medias = apply(jugadores,2,mean)
desvios = apply(jugadores,2,sd)
salida = round(cbind(medias,desvios),3)
salida
mat_df = data.frame("Lote"=factor(c(rep(1,10),rep(2,10))),
"Resistencia"=c(vector_bueno,vector_malo,vector_malo2))
ggplot(mat_df,aes(x=Lote, y=Resistencia, fill=Lote))+geom_boxplot()
mat_df.aov=aov(Resistencia~Lote, data = mat_df)
mat_df.aov
summary(mat_df.aov)
#ANOVA nos da menor a 0.05, por lo que rechazamos la hipotesis nula de que
#las medias de cada lote sean iguales.
shapiro.test(residuals(mat_df.aov))
# se cumple el supuesto de normalidad
leveneTest(mat_df$Resistencia, mat_df$Lote)
## se puede considerar que se satisface el supuesto de homocedasticidad.
##Recién acá podemos decir que se rechaza la hipotesis
#nula de igualdad de medias del analisis de la varianza.
#Interesa entonces analizar qué lotes difieren entre sí.
pairwise.t.test(mat_df$Resistencia, mat_df$Lote, p.adj = "bonferroni")
TukeyHSD(mat_df.aov, "Lote")
mat_df = data.frame("Lote"=factor(c(rep(1,10),rep(2,10),rep(3,10))),
"Resistencia"=c(vector_bueno,vector_malo,vector_malo2))
mat_df.aov=aov(Resistencia~Lote, data = mat_df)
mat_df.aov
summary(mat_df.aov)
#ANOVA nos da menor a 0.05, por lo que rechazamos la hipotesis nula de que
#las medias de cada lote sean iguales.
shapiro.test(residuals(mat_df.aov))
# se cumple el supuesto de normalidad
leveneTest(mat_df$Resistencia, mat_df$Lote)
## se puede considerar que se satisface el supuesto de homocedasticidad.
##Recién acá podemos decir que se rechaza la hipotesis
#nula de igualdad de medias del analisis de la varianza.
#Interesa entonces analizar qué lotes difieren entre sí.
pairwise.t.test(mat_df$Resistencia, mat_df$Lote, p.adj = "bonferroni")
TukeyHSD(mat_df.aov, "Lote")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
vector_bueno = c()
vector_malo = c()
vector_malo2 = c()
vector_malo3 = c()
for (i in 1:10)
{
vector_bueno <- c(vector_bueno, ftirar(0.7,10))
vector_malo <- c(vector_malo, ftirar(0.6,10))
vector_malo2 <- c(vector_malo2, ftirar(0.55,10))
vector_malo3 <- c(vector_malo3, ftirar(0.57,10))
}
#vector <- c(vector, values[i])
jugadores=cbind(vector_bueno,vector_malo,vector_malo2,vector_malo3)
medias = apply(jugadores,2,mean)
desvios = apply(jugadores,2,sd)
salida = round(cbind(medias,desvios),3)
salida
mat_df = data.frame("Lote"=factor(c(rep(1,10),rep(2,10),rep(3,10),rep(4,10))),
"Resistencia"=c(vector_bueno,vector_malo,vector_malo2,vector_malo3))
mat_df.aov=aov(Resistencia~Lote, data = mat_df)
mat_df.aov
summary(mat_df.aov)
#ANOVA nos da menor a 0.05, por lo que rechazamos la hipotesis nula de que
#las medias de cada lote sean iguales.
shapiro.test(residuals(mat_df.aov))
# se cumple el supuesto de normalidad
leveneTest(mat_df$Resistencia, mat_df$Lote)
## se puede considerar que se satisface el supuesto de homocedasticidad.
##Recién acá podemos decir que se rechaza la hipotesis
#nula de igualdad de medias del analisis de la varianza.
#Interesa entonces analizar qué lotes difieren entre sí.
pairwise.t.test(mat_df$Resistencia, mat_df$Lote, p.adj = "bonferroni")
TukeyHSD(mat_df.aov, "Lote")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
gimnasio_init  <- function()
{
GLOBAL_jugadores  <<-  c((501:599)/1000 , 0.70)
GLOBAL_tiros_total  <<- 0
}
jugadores  <-  c((501:599)/1000 , 0.70)
jugadores=cbind(vector_bueno,vector_malo,vector_malo2,vector_malo3)
jugadores
jugadores <- cbind()
jug  <-  c((501:599)/1000 , 0.70)
jugadores <- cbind()
for (i in jug)
{
vector = c()
for (j in 1:10)
{
vector <- c(vector, ftirar(i,10))
}
jugadores <- cbind(jugadores,vector)
}
jugadores
View(jugadores)
jugadores.colnames
jugadores.colnames()
colnames(jugadores)
colnames(jugadores) = c(1:100)
View(jugadores)
medias = apply(jugadores,2,mean)
desvios = apply(jugadores,2,sd)
salida = round(cbind(medias,desvios),3)
salida
c(vector_bueno,vector_malo,vector_malo2,vector_malo3)
View(mat_df)
repeticiones = c()
for (i in 1:100)
{
repeticiones = c(repeticiones,rep(i,10))
}
jugadores <- cbind()
jugad = c()
for (i in jug)
{
vector = c()
for (j in 1:10)
{
vector <- c(vector, ftirar(i,10))
}
jugadores <- cbind(jugadores,vector)
jugad = c(jugad,vector)
}
mat_df = data.frame("Jugador"=factor(repeticiones),
"Aciertos"=jugad)
View(mat_df)
mat_df.aov=aov(Aciertos~Jugador, data = mat_df)
TukeyHSD(mat_df.aov, "Jugador")
valores =TukeyHSD(mat_df.aov, "Jugador")
View(valores)
valores =TukeyHSD(mat_df.aov, "Jugador", ordered = TRUE, conf.level = 0.01)
valores =TukeyHSD(mat_df.aov, "Jugador",conf.level = 0.01)
valores =TukeyHSD(mat_df.aov, "Jugador")
valores =TukeyHSD(mat_df.aov, "Jugador", ordered = FALSE)
valores
as.data.frame(valores$Jugador)
df = as.data.frame(valores$Jugador)
View(df)
df[0]
df[0,1]
df[0,:]
df[1,]
valores =TukeyHSD(mat_df.aov, "Jugador", ordered = FALSE,conf.level = .95)
df = as.data.frame(valores$Jugador)
View(df)
valores =TukeyHSD(mat_df.aov, "Jugador", ordered = FALSE,conf.level = .99)
df = as.data.frame(valores$Jugador)
View(df)
View(df)
df.index()
index(df)
df['4-1']
df['4-1',1]
View(df)
paste("Hello", 4, sep=" ")
for (i in c(1:100))
{
df[paste("100",i, sep="-"),1]
}
for (i in c(1:100))
{
cat(df[paste("100",i, sep="-"),1])
}
for (i in c(1:100))
{
cat(df[paste("100",i, sep="-"),1]," ")
}
for (i in c(1:100))
{
cat(df[paste("1",i, sep="-"),1]," ")
}
for (i in c(1:100))
{
cat(df[paste("2",i, sep="-"),1]," ")
}
df[id %in% c(100,1),1]
df[%in% c(100,1),1]
valores =TukeyHSD(mat_df.aov, "Jugador", ordered = FALSE,conf.level = .99, group=TRUE)
df = as.data.frame(valores$Jugador)
View(df)
valores =TukeyHSD(mat_df.aov, "Jugador", ordered = FALSE,conf.level = .99, group=FALSE)
valores
valores$comparison
TukeyHSD(mat_df.aov, "Jugador", ordered = FALSE,conf.level = .99, group=FALSE,console=TRUE)
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/RepensandoOverfitting/521_arbol_canaritos_prp.r', echo=TRUE)
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/RepensandoOverfitting/521_arbol_canaritos_prp.r', echo=TRUE)
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/RepensandoOverfitting/523_arbol_canaritos_pruning.r', echo=TRUE)
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/RepensandoOverfitting/521_arbol_canaritos_prp.r', echo=TRUE)
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/ranger/411_ranger.r', echo=TRUE)
require("data.table")
require("ranger")
require("randomForest")
install.packages("randomForest")
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/ranger/411_ranger.r', echo=TRUE)
require("data.table")
require("data.table")
require("ranger")
require("randomForest")  #solo se usa para imputar nulos
install.packages("randomForestExplainer")
require("randomForest")  #solo se usa para imputar nulos
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/ranger/411_ranger.r', echo=TRUE)
require("randomForest")  #solo se usa para imputar nulos
install.packages("RandomForestsGLS")
install.packages("randomForestSRC")
require("randomForest")  #solo se usa para imputar nulos
require("randomForest")  #solo se usa para imputar nulos
install.packages("randomForest", dependencies = T)
require("randomForest")  #solo se usa para imputar nulos
require("randomForest")  #solo se usa para imputar nulos
library(recipes)
require("randomForest")  #solo se usa para imputar nulos
devtools::install_github( "decisionpatterns/na.tools")
require("randomForest")  #solo se usa para imputar nulos
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/ranger/411_ranger.r', echo=TRUE)
require("randomForest")  #solo se usa para imputar nulos
