<<<<<<< HEAD
install.packages("tinytex")
## Trabajo Práctico N°1
install.packages('tinytex')
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(readxl)
Datos <- read_excel("C:/Users/Gonzalo/Desktop/MMD/2-Estadistica/Clase 4/Datos.xlsx",
sheet = "vehiculos")
View(Datos)
#Cargamos datos
vehiculos <- read_excel("C:/Users/Gonzalo/Desktop/MMD/2-Estadistica/Clase 4/Datos.xlsx",
sheet = "vehiculos")
head(vehiculos)
glimpse(vehiculos) #DEscribe datos
glimpse(vehiculos) #DEscribe datos
#Librerias
library(readxl)
library(dplyr)
glimpse(vehiculos) #DEscribe datos
resis <- vehiculos$Resistencia
#Estadisticos
summary(resis)
View(media <-mean(resis))
media <-mean(resis)
media
#Promedio
media <-mean(resis)
media
#Mediana
mediana <-median(resis)
#Mediana
mediana <-median(resis)
mediana
install.packages("modeest")
#Moda
moda <- mode(resis)
moda
#Moda
moda <- mfv(resis)
#Librerias
library(readxl)
library(dplyr)
library(modeest)
#Moda
moda <- mfv(resis)
moda
#Max y Min
max(resis)
min(resis)
#Cuantiles
quantile(resis)
#Rango
range(resis)
#Desviacion estandar
sd(resis)
#Varianza muestral
var(resis)
#Coheficiente de variación
CV = (sd(resis)/mean(resis)) * 100
CV
#Rango intercuartilico
IQR(reses)
#Rango intercuartilico
IQR(resis)
install.packages("fBasics")
knitr::opts_chunk$set(echo = TRUE)
library(fBasics)
library(e1071)
install.packages("e1071")
library(fBasics)
library(e1071)
skewness(resis)
library(fBasics)
library(e1071)
skewness(resis)
#Curtosis
kurtosis(resis)
stem(resis)
#Numero de intervalos
nclass.Sturges(resis)
#Limite de los intervalos
seq(120,150,length= nclass.Sturges(resis))
#Limite de los intervalos
limite = seq(120,150,length= nclass.Sturges(resis))
#Limite de los intervalos
limite = seq(120,150,length= nclass.Sturges(resis))
interv_resis <- cut(resis,break = limite, include.lowest=TRUE)
interv_resis <- cut(resis,breaks = limite, include.lowest=TRUE)
#Mostramos los intervalores de resistencia en una tabla
table(interv_resis)
#Histograma
hist(resis, breaks = limite)
#Histograma
hist(resis, breaks = limite, main = "Histograma de la variable Resistencia")
#Histograma
hist(resis, breaks = limite, main = "Histograma de la variable Resistencia", col = "Red, xlab= "Intervalos", ylab = "Frecuencia")
#Histograma
hist(resis, breaks = limite, main = "Histograma de la variable Resistencia", col = "Red", xlab= "Intervalos", ylab = "Frecuencia")
knitr::opts_chunk$set(echo = TRUE)
n_i <- nclass.Sturges(edades)
#Librerias
library(dplyr)
library(modeest)
#Cargamos datos en un vector para su uso
edades <- c(21,23,56,74,55,27,23,89,77,48,77,77,76,33,23,22,55,62,64,65,77,47,45,45,45,
65,42,48,49,52,53,44,45,23,78,77,67,88,36,38,78,74,46,36,30,33,23,24,55,77,25,46,40,23,45,66,76)
#Promedio
media <-mean(edades)
media
#Mediana
mediana <-median(edades)
mediana
#Moda
moda <- mfv(edades)
moda
#Max y Min
max(edades)
min(edades)
#Cuantiles
quantile(edades)
#Rango
range(edades)
#Desviacion estandar
sd(edades)
#Varianza muestral
var(edades)
#Coheficiente de variación
CV = (sd(edades)/mean(edades)) * 100
CV
#Rango intercuartilico
IQR(edades)
n_i <- nclass.Sturges(edades)
# Distribucion de frecuencias absolutas, relativas, porcentuales:
library(fdth)
tabla_frec <-fdt_cat(edades)
#Limite de los intervalos:
limite <- seq(20,90,length= n_i)
#Limite de los intervalos:
#limite <- seq(20,90,length= n_i)
limite <- seq(20,90,by=10)
#Amplitud de intervalos:
a_i <- 10
#Limite de los intervalos:
#limite <- seq(20,90,length= n_i)
limite <- seq(20,90,by=a_i)
library(readxl)
tabla4 <-fdt_cat(edades)
knitr::opts_chunk$set(echo = TRUE)
Salud <- salud$Problemas
library(fdth)
menor_40
#Porcentaje de personas menores de 40 años:
menor_40 <- edades[edades<40]/count(edades)
#Porcentaje de personas menores de 40 años:
menor_40 <- edades[edades<40]/length(edades)
#Porcentaje de personas menores de 40 años:
menor_40 <- 100 * lenght(edades[edades<40])/length(edades)
#Porcentaje de personas menores de 40 años:
menor_40 <- 100 * length(edades[edades<40])/length(edades)
#Cantidad de personas [70;90):
entre_70_90 <- length(edades[edades >= 70 && edades < 90])
#Cantidad de personas [70;90):
entre_70_90 <- length(edades[edades >= 70 & edades < 90])
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
#Cargamos producciones:
Fertilizante_A <- c(30,25,28,29,30,31,24,22,25,27)
Fertilizante_B <- c(28,27,28,28,26,27,26,29)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
z.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
#Cargamos produccion anterior
Fertilizante_A_antes <- c(25,20,25,28,30,30,26,15,18,22)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
t.test(x=Fertilizante_A_antes,y=Fertilizante_A,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
leveneTest(Fertilizante_A_antes)
#Como ambas muestras tienen una distribución normal:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
library(car)
install.packages("car")
library(car)
leveneTest(Fertilizante_A_antes)
leveneTest(c(Fertilizante_A_antes, Fertilizante_A), rep(c("Gr1", "Gr2"), each = 15), center = "mean")
#Como ambas muestras tienen una distribución normal:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
library(effsize)
install.packages("effsize")
library(effsize)
cohen.d(Fertilizante_A_antes, Fertilizante_A, paired = FALSE)
cohen.d(Fertilizante_A_antes, Fertilizante_A, paired = FALSE, conf.level = 0.99)
cohen.d(Fertilizante_B, Fertilizante_A, paired = FALSE, conf.level = 0.98)
#Como ambas muestras tienen una distribución normal:
t.test(x=Fertilizante_A,y=Fertilizante_A_antes,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.99)
#Buscamos el intervalo de confianza para la diferencai, al 98%:
t.test(x=Fertilizante_A,y=Fertilizante_B,alternative = "two.sided",mu=0,var.equal =TRUE,conf.level = 0.98)
# Distribucion de frecuencias absolutas, relativas, porcentuales:
library(fdth)
tabla4 <-fdt(edades)
tabla4
tabla4 <-fdt(edades,start = 20,end = 90,h = a_i)
tabla4
m_organica <- c(1.10,	5.09,	0.97,	1.59,	4.60,	0.32,	0.55,	1.45,	0.14,	4.47,
1.20,	3.50,	5.02,	4.67,	5.22,	2.69,	3.98,	3.17,	3.03,	2.21)
$Prueba
$\mu
$$\mu
#Cargamos los datos a un vector:
m_organica <- c(1.10,	5.09,	0.97,	1.59,	4.60,	0.32,	0.55,	1.45,	0.14,	4.47,
1.20,	3.50,	5.02,	4.67,	5.22,	2.69,	3.98,	3.17,	3.03,	2.21)
#Calculamos intervalos de confianza al 95%:
t.test(m_organica,conf.level = 0.95)$conf.int
#Calculamos intervalos de confianza al 95%:
t.test(m_organica,conf.level = 0.95)
shapiro.test(m_organica)
install.packages("car")
knitr::opts_chunk$set(echo = TRUE)
library("car")
leveneTest(m_organica)
c_1 <- c(102,86,98,109,92)
c_2 <- c(81,165,97,134,92,87,114)
#Prueba de normalidad:
shapiro.test(c_1)
#Creamos dataframe
peliculas <- data.frame(Companias=factor(c(rep("1",5),rep("2",7))),
Tiempo=c(c_1,c_2)) peliculas
#Creamos dataframe
peliculas <- data.frame(Companias=factor(c(rep("1",5),rep("2",7))),
Tiempo=c(c_1,c_2))
peliculas
#Prueba de Homocedasticidad:
library(car)
leveneTest(Tiempo~Companias, data = peliculas)
#Prueba de hipótesis:
t.test(c_1,c_2,paired = FALSE,alternative = "greater",conf.level = 0.90,
var.equal = TRUE, mu=10)
install.packages("xelatex")
install.packages("inputenc")
#Creamos dataframe:
fertilizantes <- data.frame(fert=factor(c(rep("A",5),rep("B",7)))
, peso=c(Fertilizante_A,Fertilizante_B))
#Creamos dataframe:
fertilizantes <- data.frame(fert=factor(c(rep("A",10),rep("B",8)))
, peso=c(Fertilizante_A,Fertilizante_B))
leveneTest(peso~fert, data = fertilizantes)
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/rpart/101_PrimerModelo.R', echo=TRUE)
source('C:/Users/Gonzalo/Desktop/MMD/8- Mineria Aplicada a Finanzas/Git Clone/labo/src/rpart/101_PrimerModelo.R', echo=TRUE)
#genero el modelo,  aqui se construye el arbol
modelo1  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.5,   #esto significa no limitar la complejidad de los splits #prueba -1
minsplit=  20,     #minima cantidad de registros para que se haga el split (80)M90 Prueba 300
minbucket=  20,     #tamaÃ±o minimo de una hoja (1)M10
maxdepth=   6 )    #profundidad maxima del arbol (4)M5
modelo
modelo == modelo1
modelo = modelo1
=======
setwd("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart")
#cargo las librerias que necesito
require("data.table")
#cargo las librerias que necesito
require("data.table")
require("rpart")
#Aqui se debe poner la carpeta de SU computadora local
setwd("C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\src\\rpart")  #Establezco el Working Directory
wd
#Aqui se debe poner la carpeta de SU computadora local
setwd("C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\src\\rpart")  #Establezco el Working Directory
#cargo los datos de 202011 que es donde voy a ENTRENAR el modelo
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
#cargo los datos de 202011 que es donde voy a ENTRENAR el modelo
dtrain  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202011.csv")
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  80,     #minima cantidad de registros para que se haga el split
minbucket=  1,     #tamaño minimo de una hoja
maxdepth=   4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
require("data.table")
require("rpart")
require("rpart.plot")
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
dapply  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202101.csv")
prediccion  <- predict( modelo, dapply , type = "prob")
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60) ]
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
dir.create( "./labo/exp/" )
dir.create( "./labo/exp/KA2001" )
dir.create( "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp/" )
dir.create( "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp/KA2001")
fwrite( entrega,
file= "./labo/exp/KA2001/K101_001.csv",
sep= "," )
fwrite( entrega,
file= "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp//KA2001/K101_001.csv",
sep= "," )
View(entrega)
View(entrega)
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  40,     #minima cantidad de registros para que se haga el split (80)
minbucket=  4,     #tamaño minimo de una hoja (1)
maxdepth=   23 )    #profundidad maxima del arbol (4)
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
dapply  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202101.csv")
prediccion  <- predict( modelo, dapply , type = "prob")
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60) ]
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
fwrite( entrega,
file= "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp//KA2001/K101_001.csv",
sep= "," )
o  <-
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  150,     #minima cantidad de registros para que se haga el split (80)
minbucket=  1,     #tamaño minimo de una hoja (1)
maxdepth=   5 )    #profundidad maxima del arbol (4)
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#cargo los datos de 202011, que es donde voy a APLICAR el modelo
dapply  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202101.csv")
#aplico el modelo a los datos nuevos
prediccion  <- predict( modelo, dapply , type = "prob")
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
#solo le envio estimulo a los registros con probabilidad de BAJA+2 mayor  a  1/60
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60) ]
#genero un dataset con las dos columnas que me interesan
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
fwrite( entrega,
file= "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp//KA2001/K101_001.csv",
sep= "," )
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  90,     #minima cantidad de registros para que se haga el split (80)
minbucket=  10,     #tamaño minimo de una hoja (1)
maxdepth=   4 )    #profundidad maxima del arbol (4)
dapply  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202101.csv")
prediccion  <- predict( modelo, dapply , type = "prob")
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
#solo le envio estimulo a los registros con probabilidad de BAJA+2 mayor  a  1/60
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60) ]
#genero un dataset con las dos columnas que me interesan
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
#genero el archivo para Kaggle
#creo la carpeta donde va el experimento
dir.create( "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp/")
dir.create( "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp/KA2001")
fwrite( entrega,
file= "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp//KA2001/K101_001.csv",
sep= "," )
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  1000,     #minima cantidad de registros para que se haga el split (80)90
minbucket=  100,     #tamaño minimo de una hoja (1)10
maxdepth=   30 )    #profundidad maxima del arbol (4)4
dapply  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202101.csv")
#aplico el modelo a los datos nuevos
prediccion  <- predict( modelo, dapply , type = "prob")
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
#solo le envio estimulo a los registros con probabilidad de BAJA+2 mayor  a  1/60
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60) ]
#genero un dataset con las dos columnas que me interesan
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
#genero el archivo para Kaggle
#creo la carpeta donde va el experimento
dir.create( "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp/")
dir.create( "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp/KA2001")
fwrite( entrega,
file= "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp//KA2001/K101_001.csv",
sep= "," )
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  90,     #minima cantidad de registros para que se haga el split (80)M90
minbucket=  10,     #tamaño minimo de una hoja (1)M10
maxdepth=   5 )    #profundidad maxima del arbol (4)M4
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#Ahora aplico al modelo  a los datos de 202101  y genero la salida para kaggle
#cargo los datos de 202011, que es donde voy a APLICAR el modelo
dapply  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202101.csv")
#aplico el modelo a los datos nuevos
prediccion  <- predict( modelo, dapply , type = "prob")
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
#solo le envio estimulo a los registros con probabilidad de BAJA+2 mayor  a  1/60
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60) ]
#genero un dataset con las dos columnas que me interesan
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
#genero el archivo para Kaggle
#creo la carpeta donde va el experimento
dir.create( "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp/")
dir.create( "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp/KA2001")
fwrite( entrega,
file= "C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\exp//KA2001/K101_001.csv",
sep= "," )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
setwd("C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\src\\rpart")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202011.csv")
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= 236087 )
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed = 236087 )  #Cambiar po
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
#------------------------------------------------------------------------------
#particionar agrega una columna llamada fold a un dataset que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
#Aqui se debe poner la carpeta de la computadora local
setwd("C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\src\\rpart")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202011.csv")
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed = 236087 )
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control=  param_basicos )  #aqui van los parametros
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
dataset[  , ganancia :=  ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) ]
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
ganancia_test  <- dataset[ fold==2 & prob_baja2 >  1/60, sum(ganancia) ]
ganancia_test_normalizada  <-  ganancia_test / 0.3
cat( ganancia_test_normalizada )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
#------------------------------------------------------------------------------
#particionar agrega una columna llamada fold a un dataset que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
#Aqui se debe poner la carpeta de la computadora local
setwd("C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\src\\rpart")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202011.csv")
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed = 236107 )  #Cambiar por la primer semilla de cada uno !
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control=  param_basicos )  #aqui van los parametros
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#agrego una columna que es la de las ganancias
dataset[  , ganancia :=  ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) ]
#para testing agrego la probabilidad
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2 & prob_baja2 >  1/60, sum(ganancia) ]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
cat( ganancia_test_normalizada )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
#------------------------------------------------------------------------------
#particionar agrega una columna llamada fold a un dataset que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
#Aqui se debe poner la carpeta de la computadora local
setwd("C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\src\\rpart")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202011.csv")
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed = 236111 )  #Cambiar por la primer semilla de cada uno !
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control=  param_basicos )  #aqui van los parametros
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#agrego una columna que es la de las ganancias
dataset[  , ganancia :=  ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) ]
#para testing agrego la probabilidad
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2 & prob_baja2 >  1/60, sum(ganancia) ]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
cat( ganancia_test_normalizada )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
#------------------------------------------------------------------------------
#particionar agrega una columna llamada fold a un dataset que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
#Aqui se debe poner la carpeta de la computadora local
setwd("C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\src\\rpart")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202011.csv")
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed = 236129 )  #Cambiar por la primer semilla de cada uno !
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control=  param_basicos )  #aqui van los parametros
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#agrego una columna que es la de las ganancias
dataset[  , ganancia :=  ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) ]
#para testing agrego la probabilidad
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2 & prob_baja2 >  1/60, sum(ganancia) ]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
cat( ganancia_test_normalizada )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
#------------------------------------------------------------------------------
#particionar agrega una columna llamada fold a un dataset que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
#Aqui se debe poner la carpeta de la computadora local
setwd("C:\\Users\\Gonzalo\\Desktop\\MMD\\Git Clone\\labo\\src\\rpart")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("C:\\Users\\Gonzalo\\Desktop\\MMD\\Datasets/paquete_premium_202011.csv")
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed = 236143 )  #Cambiar por la primer semilla de cada uno !
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control=  param_basicos )  #aqui van los parametros
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#agrego una columna que es la de las ganancias
dataset[  , ganancia :=  ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) ]
#para testing agrego la probabilidad
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2 & prob_baja2 >  1/60, sum(ganancia) ]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
cat( ganancia_test_normalizada )
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
prueba = c(1,2)
prueba(1)
prueba[1]
semillas = c(236087, 236107, 236111, 236129, 236143)
for (i in semillas)
{
cat(i)
}
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/211_traintest_estratificado.r")
clear
clear()
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/222_traintest_montecarlo.r")
mean(unlist(ganancias))
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/222_traintest_montecarlo.r")
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/222_traintest_montecarlo.r", echo=TRUE)
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/222_traintest_montecarlo.r", echo=TRUE)
source("C:/Users/Gonzalo/Desktop/MMD/Git Clone/labo/src/rpart/231_mejormodelo.r", echo=TRUE)
<<<<<<< HEAD
>>>>>>> 651be16 (prueba)
=======
>>>>>>> 08da12797827cabda4405bcf4e20cc7d7f09620b
>>>>>>> 4541cc1be6e1bc1d8a061d505a3ec727ede9351e
